{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84fb55c1-e47c-480f-9994-45eea5512bb5",
   "metadata": {},
   "source": [
    "# 02 — Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f617d-a0eb-436d-b968-b2d0afd52321",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669a53a-ea3c-4cce-977b-aab37a598bc3",
   "metadata": {},
   "source": [
    "This notebook brings together the full modeling workflow: training baseline models, tuning their hyperparameters, and selecting the final model for interpretation and reporting. After completing the data cleaning (Notebook 00) and exploratory data analysis (Notebook 01), we now have a clear understanding of the dataset’s structure and the key variables that influence the target. The next step is to translate these insights into predictive performance.\n",
    "\n",
    "In this notebook, we will:\n",
    "\n",
    "* Prepare the cleaned dataset for modeling (feature selection, encoding, scaling)\n",
    "\n",
    "* Train baseline models to establish reference performance\n",
    "\n",
    "* Perform hyperparameter tuning using systematic search strategies\n",
    "\n",
    "* Compare tuned models to identify the best-performing approach\n",
    "\n",
    "* Train the final model using the optimal hyperparameters\n",
    "\n",
    "* Evaluate the final model on unseen data\n",
    "\n",
    "* Analyze feature importance and interpretability where relevant\n",
    "\n",
    "By combining model training, tuning, and final selection into a single workflow, this notebook provides a complete and transparent modeling pipeline. The final output of this notebook will be the fully trained model that will be used for interpretation, reporting, and any downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c74e1d-d76d-4c6f-954e-6cfdac5a4296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:10:54.376095Z",
     "iopub.status.busy": "2026-01-11T05:10:54.375626Z",
     "iopub.status.idle": "2026-01-11T05:10:54.389370Z",
     "shell.execute_reply": "2026-01-11T05:10:54.389370Z",
     "shell.execute_reply.started": "2026-01-11T05:10:54.376095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added: C:\\Users\\shari\\OneDrive\\MSc Data Science and Society\\Thesis_DSS_2026\n",
      "Data directory: C:\\Users\\shari\\OneDrive\\MSc Data Science and Society\\Thesis_DSS_2026\\data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Determine the project root (one level above the notebook directory)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "\n",
    "# Add project root to Python path so modules in /src can be imported\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added:\", project_root)\n",
    "\n",
    "# Build data directory path\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "print(\"Data directory:\", data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169db52-c751-4a49-9d68-5fa7dfb835ec",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c221ae-f922-404c-b778-0edbc3f72f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:10:54.425964Z",
     "iopub.status.busy": "2026-01-11T05:10:54.425964Z",
     "iopub.status.idle": "2026-01-11T05:10:59.500522Z",
     "shell.execute_reply": "2026-01-11T05:10:59.500522Z",
     "shell.execute_reply.started": "2026-01-11T05:10:54.425964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from src.modeling import (\n",
    "    evaluate_model,\n",
    "    run_all_models_for_regime,\n",
    "    run_median_baseline,\n",
    "    run_ridge,\n",
    "    run_rf,\n",
    "    run_xgb,\n",
    "    run_all_models_for_regime\n",
    ")\n",
    "\n",
    "from src.model_comparison import (\n",
    "    build_cross_model_comparison,\n",
    "    compare_models,\n",
    "    run_pairwise_tests\n",
    ")\n",
    "# Config\n",
    "from src.config import GLOBAL_CONFIG\n",
    "\n",
    "# EDA\n",
    "from src.eda import (\n",
    "    inspect_regime,\n",
    "    run_full_eda,\n",
    "    list_sorted_correlations,\n",
    "    target_summary\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from src.metrics import (\n",
    "    rmse,\n",
    "    mae,\n",
    "    r2,\n",
    "    error_analysis,\n",
    "    bootstrap_rmse_ci\n",
    ")\n",
    "\n",
    "# feature filtering \n",
    "from src.feature_filtering import (\n",
    "    drop_high_missing_cols, \n",
    "    drop_constant_and_near_constant_cols,\n",
    "    drop_multicollinear_cols\n",
    ")\n",
    "\n",
    "# Feature engineering\n",
    "from src.data_preparation import (\n",
    "    prepare_data,\n",
    "    build_preprocessor\n",
    ")\n",
    "\n",
    "# feature importances \n",
    "from src.feature_importance import (\n",
    "    get_feature_names,\n",
    "    ridge_coefficients,\n",
    "    rf_gini_importance,\n",
    "    xgb_importance\n",
    ")\n",
    "\n",
    "# Transformations\n",
    "from src.transforms import (\n",
    "    detect_col_types,\n",
    "    inverse_target_corrected, \n",
    "    LogTransformer, \n",
    "    inverse_target,\n",
    "    transform_target\n",
    ")\n",
    "\n",
    "from src.feature_engineering import build_preprocessor\n",
    "# Plotting\n",
    "from src.plotting import (\n",
    "    plot_error_distribution,\n",
    "    plot_per_fold_rmse,\n",
    "    plot_predicted_vs_actual\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d12bdb-5fcf-42a0-9524-e84288596ae9",
   "metadata": {},
   "source": [
    "## 3. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2255dcfa-514f-47d0-ad92-c8306a8ad659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:10:59.560935Z",
     "iopub.status.busy": "2026-01-11T05:10:59.558920Z",
     "iopub.status.idle": "2026-01-11T05:11:00.499882Z",
     "shell.execute_reply": "2026-01-11T05:11:00.499882Z",
     "shell.execute_reply.started": "2026-01-11T05:10:59.560935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_clean = pd.read_parquet(os.path.join(data_dir, \"clean\", \"df_clean.parquet\"))\n",
    "\n",
    "df_regime_a = pd.read_parquet(os.path.join(data_dir, \"regimes\", \"regime_a.parquet\"))\n",
    "df_regime_b = pd.read_parquet(os.path.join(data_dir, \"regimes\", \"regime_b.parquet\"))\n",
    "df_regime_c = pd.read_parquet(os.path.join(data_dir, \"regimes\", \"regime_c.parquet\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980a5bb8-aa9a-4284-8e5f-d4d27d5a54a8",
   "metadata": {},
   "source": [
    "## 4. Model Training, Hyperparameter Tuning, Model Evauation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966cac5-acca-453a-a896-57f0c928b513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T05:11:00.694007Z",
     "iopub.status.busy": "2026-01-11T05:11:00.691403Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RUNNING FULL EXPERIMENT – Regime A\n",
      "================================================================================\n",
      "Dropped (high missing): ['006', '009', '031', '033', '036', '038', '039', '040', '042', '043', '044', '045', '046', '047', '049', '050', '051', '052', '053', '055', '056', '057', '059', '060', '061', '062', '063', '064', '066', '067', '068', '069', '070', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '083', '084', '086', '087', '103', '104', '105', '106', '107', '108', '109', '110', '111', '113', '114', '115', '116', '117', '118', '119', '120', '124', '125', '128', '129', '130', '131', '133', '135', '137', '138', '139', '144', '308', '309', '310', '311', '312', '314', '315', '316', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '381', '386', '387', '388', '389', '410', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '440', '441', '442', '443', '444', '445', '447', '448', '449', '451', '452', '453', '454', '455', '456', '457', '458', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '524', '511', '512', '513', '514', '515', '517', '518', '519', '520', '521', '510', '526', '530', '529', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '572', '573', '574', '575', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613']\n",
      "Dropped (near-constant): ['001', '089', '090', '091', '092', '093', '094', '097', '098']\n",
      "Dropped (multicollinear): []\n",
      "Dropped (high missing): ['006', '009', '031', '033', '036', '038', '039', '040', '042', '043', '044', '045', '046', '047', '049', '050', '051', '052', '053', '055', '056', '057', '059', '060', '061', '062', '063', '064', '066', '067', '068', '069', '070', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '083', '084', '086', '087', '103', '104', '105', '106', '107', '108', '109', '110', '111', '113', '114', '115', '116', '117', '118', '119', '120', '124', '125', '128', '129', '130', '131', '133', '135', '137', '138', '139', '144', '308', '309', '310', '311', '312', '314', '315', '316', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '381', '386', '387', '388', '389', '410', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '440', '441', '442', '443', '444', '445', '447', '448', '449', '451', '452', '453', '454', '455', '456', '457', '458', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '524', '511', '512', '513', '514', '515', '517', '518', '519', '520', '521', '510', '526', '530', '529', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '572', '573', '574', '575', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613']\n",
      "Dropped (near-constant): ['001', '089', '090', '091', '092', '093', '094', '097', '098']\n",
      "Dropped (multicollinear): []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shari\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 3 is smaller than n_iter=8. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped (high missing): ['006', '009', '031', '033', '036', '038', '039', '040', '042', '043', '044', '045', '046', '047', '049', '050', '051', '052', '053', '055', '056', '057', '059', '060', '061', '062', '063', '064', '066', '067', '068', '069', '070', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '083', '084', '086', '087', '103', '104', '105', '106', '107', '108', '109', '110', '111', '113', '114', '115', '116', '117', '118', '119', '120', '124', '125', '128', '129', '130', '131', '133', '135', '137', '138', '139', '144', '308', '309', '310', '311', '312', '314', '315', '316', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '381', '386', '387', '388', '389', '410', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '440', '441', '442', '443', '444', '445', '447', '448', '449', '451', '452', '453', '454', '455', '456', '457', '458', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '524', '511', '512', '513', '514', '515', '517', '518', '519', '520', '521', '510', '526', '530', '529', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '572', '573', '574', '575', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613']\n",
      "Dropped (near-constant): ['001', '089', '090', '091', '092', '093', '094', '097', '098']\n",
      "Dropped (multicollinear): []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ALL_RESULTS = {}\n",
    "\n",
    "# Dictionary of regime names and their corresponding datasets\n",
    "regimes = {\n",
    "    \"Regime A\": df_regime_a,\n",
    "    \"Regime B\": df_regime_b,\n",
    "    \"Regime C\": df_regime_c\n",
    "}\n",
    "\n",
    "# Execute full modeling workflow for each regime\n",
    "for regime_name, df_regime in regimes.items():\n",
    "    ALL_RESULTS[regime_name] = run_all_models_for_regime(\n",
    "        regime_name=regime_name,\n",
    "        df=df_regime,\n",
    "        config=GLOBAL_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788d876-ccbf-4658-9716-028aa5166d2b",
   "metadata": {},
   "source": [
    "## 3. Best Hyperparamets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f578a-a9c3-4dd2-b7bc-a13f723e4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispaly best parameters for each model in each regime\n",
    "\n",
    "for regime_name, regime_data in ALL_RESULTS.items():\n",
    "    print(f\"\\n===== {regime_name} – Best Hyperparameters =====\")\n",
    "    for model_name, model_res in regime_data[\"results\"].items():\n",
    "        print(f\"{model_name}: {model_res['best_params_overall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa29be-6f3f-46e9-95f4-44f1fbba6526",
   "metadata": {},
   "source": [
    "## 4. Model Comparison & Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf0f04b-5b79-4e60-aca1-112b2021b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for regime in [\"Regime A\", \"Regime B\", \"Regime C\"]:\n",
    "    print(f\"\\n===== {regime} – Model Comparison =====\")\n",
    "    print(ALL_RESULTS[regime][\"comparison_table\"])\n",
    "\n",
    "    print(f\"\\n===== {regime} – Statistical Tests =====\")\n",
    "    print(ALL_RESULTS[regime][\"stats_table\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd45c7-3842-4107-9055-9ee53bc8e3df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for regime, res in ALL_RESULTS.items():\n",
    "    print(f\"\\n=== {regime} ===\")\n",
    "    \n",
    "    for model_name, model_res in res[\"results\"].items():\n",
    "        print(f\"\\n--- {model_name} ---\")\n",
    "        \n",
    "        preds = pd.DataFrame({\n",
    "            \"y_true\": model_res[\"y_test_true\"],\n",
    "            \"y_pred\": model_res[\"y_test_pred\"]\n",
    "        })\n",
    "        \n",
    "        display(preds.head())   # show first few rows\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18760779-9076-460b-89fc-8c181d030fa8",
   "metadata": {},
   "source": [
    "for regime, res in ALL_RESULTS.items():\n",
    "    for model_name, model_res in res[\"results\"].items():\n",
    "        if \"ridge_coefficients\" in model_res:\n",
    "            model_res[\"ridge_coefficients\"].to_csv(f\"results/{regime}_ridge_coeffs.csv\", index=False)\n",
    "        if \"gini_importance\" in model_res:\n",
    "            model_res[\"gini_importance\"].to_csv(f\"results/{regime}_rf_importance.csv\", index=False)\n",
    "        if \"xgb_gain\" in model_res:\n",
    "            model_res[\"xgb_gain\"].to_csv(f\"results/{regime}_xgb_gain.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe96d40b-2e66-42fd-9694-e487eff8fa29",
   "metadata": {},
   "source": [
    "## 5. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bafa5-93e2-4d4b-a1a0-aad8ec270a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "joblib.dump(ALL_RESULTS, \"results/all_results.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
